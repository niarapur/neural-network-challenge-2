{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alIIEHibGc3M"
   },
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "6eDUJ4NtGc3P",
    "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#  Import and read the attrition data\n",
    "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
    "attrition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g22aQSY4Gc3Q",
    "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
   },
   "outputs": [],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "attrition_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50vMgBEnJbfM"
   },
   "outputs": [],
   "source": [
    "# Create y_df with the Attrition and Department columns\n",
    "y_df_dept = attrition_df[['Department']]\n",
    "y_df_attr = attrition_df[['Attrition']]\n",
    "#y_df_dept.head()\n",
    "#y_df_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Virka0zLGc3R",
    "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
   },
   "outputs": [],
   "source": [
    "# Create a list of at least 10 column names to use as X data\n",
    "# Create X_df using your selected columns\n",
    "\n",
    "X_df = attrition_df[['Age','Education','EducationField','EnvironmentSatisfaction','HourlyRate', 'JobInvolvement',\n",
    "                'JobSatisfaction', 'MaritalStatus','NumCompaniesWorked','PercentSalaryHike','PerformanceRating',  \n",
    "                'StockOptionLevel','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager' ]]\n",
    "\n",
    "# Show the data types for X_df\n",
    "\n",
    "X_df.info()\n",
    "X_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaJfdOGUMHMR"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train_dept, y_test_dept,y_train_attr,y_test_attr = train_test_split(X_df, y_df_dept, y_df_attr)\n",
    "#X_train.head()\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_counts = y_train_dept.groupby('Department').size()\n",
    "department_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_counts = y_train_attr.groupby('Attrition').size()\n",
    "attr_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYubUJqiLCSp",
    "outputId": "53f31721-571c-4c94-d13e-25a715749593"
   },
   "outputs": [],
   "source": [
    "# Convert your X data to numeric data types however you see fit\n",
    "# Add new code cells as necessary\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Preprocess \"EducationField\" column (one-hot encoding for multiple categories)\n",
    "eduf_encoder = OneHotEncoder(sparse_output=False)\n",
    "eduf_encoded = eduf_encoder.fit_transform(X_train[['EducationField']])\n",
    "eduf_columns = eduf_encoder.get_feature_names_out(['EducationField'])\n",
    "\n",
    "X_train_eduf_encoded = pd.DataFrame(eduf_encoded, columns=eduf_columns)\n",
    "\n",
    "X_test_eduf = eduf_encoder.transform(X_test[['EducationField']])\n",
    "\n",
    "X_test_eduf_encoded = pd.DataFrame(X_test_eduf, columns=eduf_columns)\n",
    "\n",
    "\n",
    "# Preprocess \"MaritalStatus\" column (label encoding for binary)\n",
    "mar_encoder = LabelEncoder()\n",
    "X_train['marital_status_encoded'] = mar_encoder.fit_transform(X_train['MaritalStatus'])\n",
    "X_test['marital_status_encoded'] = mar_encoder.transform(X_test['MaritalStatus'])\n",
    "\n",
    "# Concatenate the encoded columns to the original DataFrame\n",
    "X_train_processed = pd.concat([X_train, X_train_eduf_encoded], axis=1)\n",
    "X_test_processed = pd.concat([X_test, X_test_eduf_encoded], axis=1)\n",
    "\n",
    "# Drop the original \"EducationField\" and \"MaritalStatus\" columns\n",
    "X_train_processed = X_train_processed.drop(['EducationField', 'MaritalStatus'], axis=1)\n",
    "X_test_processed = X_test_processed.drop(['EducationField', 'MaritalStatus'], axis=1)\n",
    "\n",
    "\n",
    "X_train_processed.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWA-aIA5Gc3T"
   },
   "outputs": [],
   "source": [
    "# Create a StandardScaler\n",
    "# Fit the StandardScaler to the training data\n",
    "scaler = StandardScaler().fit(X_train_processed)\n",
    "# Scale the training and testing data\n",
    "X_train_scaled = scaler.transform(X_train_processed)\n",
    "X_test_scaled = scaler.transform(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z0Mky8vQSz4",
    "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
   },
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder for the Department column\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "y_train_dept.reset_index(drop=True, inplace=True)\n",
    "y_test_dept.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dept_encoder = OneHotEncoder(sparse_output=False)\n",
    "dept_encoded = dept_encoder.fit_transform(y_train_dept[['Department']])\n",
    "dept_columns = dept_encoder.get_feature_names_out(['Department'])\n",
    "\n",
    "y_train_dept_encoded = pd.DataFrame(dept_encoded, columns=dept_columns)\n",
    "\n",
    "y_test_depte = dept_encoder.transform(y_test_dept[['Department']])\n",
    "\n",
    "y_test_dept_encoded = pd.DataFrame(y_test_depte, columns=dept_columns)\n",
    "\n",
    "# Concatenate the encoded columns to the original DataFrame\n",
    "y_train_dept_processed = pd.concat([y_train_dept, y_train_dept_encoded], axis=1)\n",
    "y_test_dept_processed = pd.concat([y_test_dept, y_test_dept_encoded], axis=1)\n",
    "\n",
    "# Drop the origienal \"Department\" column\n",
    "y_train_dept_processed = y_train_dept_processed.drop(['Department'], axis=1)\n",
    "y_test_dept_processed = y_test_dept_processed.drop(['Department'], axis=1)\n",
    "y_train_dept_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-G4DSpvFRrk4",
    "outputId": "9842e948-8a55-4b80-8fac-f96714e85589",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder for the Attrition column\n",
    "#Fit the encoder to the training data\n",
    "# Create two new variables by applying the encoder\n",
    "# to the training and testing data\n",
    "y_train_attr.reset_index(drop=True, inplace=True)\n",
    "y_test_attr.reset_index(drop=True, inplace=True)\n",
    "\n",
    "attr_encoder = OneHotEncoder(sparse_output=False)\n",
    "attr_encoded = attr_encoder.fit_transform(y_train_attr[['Attrition']])\n",
    "attr_columns = attr_encoder.get_feature_names_out(['Attrition'])\n",
    "\n",
    "y_train_attr_encoded = pd.DataFrame(attr_encoded, columns=attr_columns)\n",
    "\n",
    "y_test_attre = attr_encoder.transform(y_test_attr[['Attrition']])\n",
    "\n",
    "y_test_attr_encoded = pd.DataFrame(y_test_attre, columns=attr_columns)\n",
    "\n",
    "# Concatenate the encoded columns to the original DataFrame\n",
    "y_train_attr_processed_fin = pd.concat([y_train_attr, y_train_attr_encoded], axis=1)\n",
    "y_test_attr_processed_fin = pd.concat([y_test_attr, y_test_attr_encoded], axis=1)\n",
    "\n",
    "# Drop the original \"Department\" column\n",
    "y_train_attr_processed_fin = y_train_attr_processed_fin.drop(['Attrition'], axis=1)\n",
    "y_test_attr_processed_fin = y_test_attr_processed_fin.drop(['Attrition'], axis=1)\n",
    "y_train_attr_processed_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykNmu_WWGc3T"
   },
   "source": [
    "## Create, Compile, and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUptZqmSGc3T"
   },
   "outputs": [],
   "source": [
    "# Find the number of columns in the X training data\n",
    "num_col_x= X_train_scaled.shape[1]\n",
    "print(num_col_x)\n",
    "# Create the input layer\n",
    "input_layer = layers.Input(shape= (X_train_scaled.shape[1],), name='input_layer')\n",
    "\n",
    "# Create at least two shared layers\n",
    "shared_layer1 = layers.Dense(64, activation='relu', name = 'shared1')(input_layer)\n",
    "shared_layer2 = layers.Dense(32, activation='relu',name= 'shared2')(shared_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JukjTm2yTEqd"
   },
   "outputs": [],
   "source": [
    "# Create a branch for Department\n",
    "# with a hidden layer and an output layer\n",
    "department_dense = layers.Dense(64, activation='relu', name='department_hidden')(shared_layer2)\n",
    "department_output = layers.Dense(3,\n",
    "                             activation='softmax',\n",
    "                             name='department_output')(department_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OqhUiOJUBkR"
   },
   "outputs": [],
   "source": [
    "# Create a branch for Attrition\n",
    "# with a hidden layer and an output layer\n",
    "# Create the hidden layer\n",
    "# Create the output layer\n",
    "attrition_dense = layers.Dense(64, activation='relu',name='attrition_hidden')(shared_layer2)\n",
    "attrition_output = layers.Dense(2,\n",
    "                             activation='sigmoid',\n",
    "                             name='attrition_output')(attrition_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twmuejdxGc3T",
    "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[\n",
    "    department_output,\n",
    "    attrition_output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'department_output': 'categorical_crossentropy',\n",
    "                    'attrition_output': 'binary_crossentropy'},\n",
    "              metrics={'department_output': 'accuracy',\n",
    "                       'attrition_output': 'accuracy'})\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8oGy0dpGc3U",
    "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    {'department_output': y_train_dept_processed, 'attrition_output':y_train_attr_processed_fin},\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsMoaQlgGc3U",
    "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model with the testing data\n",
    "test_results = model.evaluate(X_test_scaled, {'department_output': y_test_dept_processed, 'attrition_output': y_test_attr_processed_fin})\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlCtlHi0Vt54",
    "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
   },
   "outputs": [],
   "source": [
    "# Print the accuracy for both department and attrition\n",
    "print(f\"Department Accuracy: {test_results[1]}\")\n",
    "print(f\"Attrition Accuracy: {test_results[2]}\")\n",
    "\n",
    "#Attrition Accuracy: 0.883152186870575\n",
    "#Department Accuracy: 0.7853260636329651"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSyfsZfWOQM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In the provided space below, briefly answer the following questions.\n",
    "\n",
    "1. Is accuracy the best metric to use on this data? Why or why not?\n",
    "\n",
    "2. What activation functions did you choose for your output layers, and why?\n",
    "\n",
    "3. Can you name a few ways that this model might be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi9SLpFnWvbF"
   },
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. While accuracy gives us a directional view of the mertic it is not the best indicator due to the skews present that can cause a class imbalance in Department and Attrition data. Based on the distributions seen, Department is showing a skew to R&D\n",
    "Department\n",
    "Human Resources            47\n",
    "Research & Development    713\n",
    "Sales                     342\n",
    "Similarly attrition has a higher number of Nos compared to Yes:\n",
    "Attrition\n",
    "No     924\n",
    "Yes    178\n",
    "\n",
    "For both the above attributes, the accuarcy score may only be valid for the majority class and not the minority class.\n",
    "\n",
    "\n",
    "2. The activation function I used for the department output layer is 'softmax'. Softmax is the activation function of choice for the output layer of a model when dealing with multi-class classification, where each input belongs to one and only one class out of several possible classes. This was the ideal choice as the classes for both were also mutually exclusive. For the 'Attrition' output layer I used sigmoid with binary cross entropy as it is predicting a 'Yes', 'No'.\n",
    "\n",
    "4. the model can be further improved by treating the data imbalance via under sampling. This could lead to a more balanced input and impact accuracy positively. testing with additional dense layers can also improve accuracy.Hyper parameter tuning is also a process to help increase acciracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
